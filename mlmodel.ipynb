{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlmodel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "054OWQ3f1FWU",
        "outputId": "d20f07e7-51b6-478c-9b95-7deadb423627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Libraries imported\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "print(\"Libraries imported\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/gsamansharma/Telegram-bot-for-spam-detection/main/spam.csv', encoding='ISO-8859-1')\n",
        "le = LabelEncoder()\n"
      ],
      "metadata": {
        "id": "sAnd9__e1It0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['v1','v2']]"
      ],
      "metadata": {
        "id": "g4y3fwre1VIy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = data.iloc[:, 1]\n",
        "y = data.iloc[:, 0]"
      ],
      "metadata": {
        "id": "nNXBAlsY1XYy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer('\\w+')\n",
        "sw = stopwords.words('english')"
      ],
      "metadata": {
        "id": "cWzlZkUu1ZZe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "fK5OCJgV1cwn"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def getStem(review):\n",
        "    review = review.lower()\n",
        "    tokens = tokenizer.tokenize(review) # breaking into small words\n",
        "    removed_stopwords = [w for w in tokens if w not in sw]\n",
        "    stemmed_words = [ps.stem(token) for token in removed_stopwords]\n",
        "    clean_review = ' '.join(stemmed_words)\n",
        "    return clean_review"
      ],
      "metadata": {
        "id": "1EBaUr9O1de_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDoc(document):\n",
        "    d = []\n",
        "    for doc in document:\n",
        "        d.append(getStem(doc))\n",
        "    return d"
      ],
      "metadata": {
        "id": "trNBkoAJ1gLU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "stemmed_doc = getDoc(X)\n",
        "\n",
        "cv = CountVectorizer()\n",
        "\n",
        "vc = cv.fit_transform(stemmed_doc)\n",
        "\n",
        "X = vc.todense()\n",
        "\n"
      ],
      "metadata": {
        "id": "qM489eO31a9c"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import model_selection"
      ],
      "metadata": {
        "id": "am-rp23L1oCc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "MQwbPh-z1p0_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import pickle"
      ],
      "metadata": {
        "id": "XHzl7gB11sHr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "naivee = MultinomialNB()\n",
        "naivee.fit(X_train, y_train)\n",
        "naivee.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YZPCGZV1tup",
        "outputId": "175952bc-2d4f-45cf-907c-6c41c7752a7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.977705274605764"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['transformed_text'] = df['v2'].apply(getStem)"
      ],
      "metadata": {
        "id": "ALto1_aX32w6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "b56b6a0d"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "cv = CountVectorizer()\n",
        "tfidf = TfidfVectorizer(max_features=3000)\n",
        "\n",
        "X = tfidf.fit_transform(df['transformed_text']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pickle.dump(naivee, open('model.pkl', 'wb'))\n",
        "pickle.dump(tfidf,open('vectorizer.pkl','wb'))"
      ],
      "metadata": {
        "id": "lrwAIWex1uh3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "u7HFQ2122JAX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "message = [\n",
        "    \"\"\"\n",
        "    England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/Ì¼1.20\n",
        "    \"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "otMh3MQ91zE5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare(message):\n",
        "    d = getDoc(message)\n",
        "    # dont do fit_transform!! it will create new vocab.\n",
        "    return cv.transform(d)"
      ],
      "metadata": {
        "id": "oDQ0Mn8z11A9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "message = prepare(message)\n"
      ],
      "metadata": {
        "id": "h5TlnDx511jz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(message)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqx2PH9R13cU",
        "outputId": "af0df118-b980-4679-bac5-c7ecb73496af"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['spam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oMHTHKq_1543"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}